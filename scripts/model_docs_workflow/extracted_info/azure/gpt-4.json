{
  "model_info": {
    "description": "GPT-4 is a large multimodal model developed by OpenAI that accepts text and image inputs to produce text outputs. It features a 8,192-token (8K) standard context window and a 32,768-token (32K) extended variant, with training data cutoff in September 2021. The model demonstrates human-level performance on professional and academic benchmarks, with enhanced reasoning, creativity, and safety alignment compared to earlier versions.",
    "tags": [],
    "tasks": [],
    "use_cases": [
      "Legal contract analysis and research",
      "Medical research assistance and reasoning",
      "Academic problem-solving and essay writing",
      "Creative content generation (writing, marketing, education)",
      "Programming tasks including code generation and debugging"
    ],
    "strengths": [
      "Demonstrates human-level performance on professional and academic benchmarks (e.g., 90th percentile on Uniform Bar Exam)",
      "Supports multimodal inputs combining text and images for tasks like visual question answering and document analysis",
      "Advanced reasoning capabilities with 86.4% accuracy on MMLU (5-shot) and 95.3% on HellaSwag (10-shot)",
      "Enhanced safety measures and ethical alignment with built-in content filtering",
      "Function calling support in 0613+ versions for structured outputs and API integration"
    ],
    "limitations": [
      "Knowledge cutoff limited to September 2021 (varies by model version)",
      "Context window limitations (8K or 32K tokens) may restrict handling of very long inputs",
      "Potential for generating plausible but incorrect information (hallucinations)",
      "Higher cost compared to GPT-3.5 Turbo ($0.03-$0.12 per 1K tokens)",
      "May struggle with extremely complex multi-step reasoning tasks"
    ],
    "languages": []
  },
  "model_evals": [
    {
      "name": "Uniform Bar Exam",
      "score": 90
    },
    {
      "name": "LSAT",
      "score": 88
    },
    {
      "name": "SAT Math",
      "score": 89
    },
    {
      "name": "SAT Reading",
      "score": 93
    },
    {
      "name": "MMLU",
      "score": 86.4
    },
    {
      "name": "HellaSwag",
      "score": 95.3
    },
    {
      "name": "ARC",
      "score": 96.3
    },
    {
      "name": "WinoGrande",
      "score": 87.5
    },
    {
      "name": "HumanEval",
      "score": 67.0
    }
  ],
  "model_name": "gpt-4",
  "provider": "azure",
  "extraction_date": "2025-07-23T08:58:32.897675"
}