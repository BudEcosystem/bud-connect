# GPT-4-0613 Model Documentation

## Overview
GPT-4-0613 is a specific snapshot version of OpenAI's GPT-4 model released on June 13, 2023. This is a static model that does not receive updates and represents a specific point-in-time version of GPT-4's capabilities.

## Technical Specifications

### Context Length
- **Context Window**: 8,192 tokens
- Maximum input and output combined cannot exceed 8,192 tokens

### Model Architecture
- Large language model based on the GPT-4 architecture
- Transformer-based neural network
- Trained on diverse internet data up to the model's knowledge cutoff

## Release Information

### Release Date
- **Official Release**: June 13, 2023
- **Version Identifier**: gpt-4-0613
- **Model Type**: Snapshot version (no ongoing updates)

### Deprecation Status
- **Current Status**: Still available as of July 2025
- **Support Period**: Extended support granted after user feedback
- **Maintenance Mode**: No updates or improvements being made
- **Future Deprecation**: Expected to be deprecated when newer versions are released, but no specific end date announced

## Pricing Structure

### Token Costs
- **Input Tokens**: $0.03 per 1,000 tokens
- **Output Tokens**: $0.06 per 1,000 tokens
- **Billing Model**: Pay-per-token usage
- **Currency**: USD

## Capabilities

### Function Calling Support
- **Status**: ✅ **SUPPORTED**
- **Functionality**: Can intelligently choose to call functions based on user input
- **Output Format**: Returns JSON objects containing function arguments
- **Reliability**: Improved function calling accuracy compared to earlier versions
- **API Parameters**: Uses `tools` and `tool_choice` parameters (newer API versions)

### Vision Capabilities
- **Status**: ❌ **NOT SUPPORTED**
- **Alternative**: Use `gpt-4-vision-preview` for vision capabilities
- **Limitation**: Vision and function calling are mutually exclusive in current OpenAI models

### Text Generation
- **Quality**: High-quality text generation and reasoning
- **Use Cases**: Complex reasoning, creative writing, code generation, analysis
- **Language Support**: Multi-language capabilities

## API Integration

### Model Name
```
gpt-4-0613
```

### API Endpoint
- Uses OpenAI's Chat Completions API
- Standard REST API integration
- Compatible with OpenAI SDKs and libraries

### Request Format
```json
{
  "model": "gpt-4-0613",
  "messages": [...],
  "tools": [...],  // For function calling
  "tool_choice": "auto"  // Function calling control
}
```

## Comparison with Related Models

### GPT-4-32K-0613
- **Context Window**: 32,768 tokens (4x larger)
- **Pricing**: Higher cost per token
- **Use Case**: Long document processing

### GPT-4 (Latest)
- **Updates**: Receives ongoing improvements
- **Stability**: May have behavior changes over time
- **Recommendation**: Use GPT-4-0613 for consistent behavior

## Best Practices

### When to Use GPT-4-0613
- Need consistent, reproducible model behavior
- Require function calling capabilities
- Working on applications where model stability is critical
- Budget-conscious applications (lower cost than GPT-4-32K)

### Migration Considerations
- Plan for eventual model deprecation
- Test newer models before migration
- Consider function calling requirements when choosing alternatives
- Monitor OpenAI deprecation announcements

## Limitations

1. **No Vision Support**: Cannot process images or visual content
2. **Static Model**: No improvements or updates after June 2023
3. **Context Limit**: 8K token limit may be restrictive for long documents
4. **Knowledge Cutoff**: Training data has a specific cutoff date
5. **Function Calling vs Vision**: Cannot combine both capabilities in a single model

## Support and Resources

### Official Documentation
- OpenAI Platform Documentation
- API Reference guides
- Function calling guides

### Community Resources
- OpenAI Developer Community
- Stack Overflow discussions
- GitHub issues and examples

This comprehensive documentation provides all the essential information about GPT-4-0613, including its specifications, capabilities, limitations, and current status. The model remains a solid choice for applications requiring stable function calling capabilities without vision processing needs.